{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTAQw61q7TdC6SsEymRiOf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flavio-mota/introd-analise-dados/blob/main/Limpeza_e_prepara%C3%A7%C3%A3o_de_dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span style=\"color:#336699\">Limpeza e preparação de dados</span>\n",
        "<hr style=\"border:2px solid #0077b9;\">\n",
        "\n",
        "<br/>\n",
        "\n",
        "<div style=\"text-align: center;font-size: 90%;\">\n",
        "    Autores:<br/>\n",
        "    Flávio Belizário da Silva Mota<br/>\n",
        "    Melise Maria Veiga de Paula\n",
        "    <br/>\n",
        "\n"
      ],
      "metadata": {
        "id": "h4VekaeueFji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivos gerais:\n",
        "\n",
        "\n",
        "*   Apresentar alguns códigos, em python, que podem ser usados para limpeza e preparação de dados, como:\n",
        "  *   Tratar dados ausentes\n",
        "  *   Transformações de dados\n"
      ],
      "metadata": {
        "id": "IGtCWKFDeiOK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurando o ambiente\n",
        "\n",
        "O Colab já vem configurado com muitas biblioteca úteis para o desenvolvimento de notebooks jupyter com python. Entre essas bibliotecas, temos a `pandas` e a `numpy`, que utilizaremos nessa aula.\n",
        "\n",
        "No nosso caso, não precisaremos instalar essas bibliotecas, apenas importá-las. Já a biblioteca `fuzzywuzzy` precisará ser instalada. Ela é uma bibliotecaque  implementa algoritmos baseados na distância de Levenshtein para calcular a diferença entre strings."
      ],
      "metadata": {
        "id": "7stCbvmjgYTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy python-Levenshtein"
      ],
      "metadata": {
        "id": "vHP_UIeWGygj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYb_7130YgyQ"
      },
      "outputs": [],
      "source": [
        "# É um padrão da comunidade a importação das bibliotecas com um \"apelido\",\n",
        "# para facilitar o uso posteriormente. Então a pandas será chamada por pd e\n",
        "# a numpy por np ao longo do código.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from fuzzywuzzy import process, fuzz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregando os dados\n",
        "\n",
        "Vamos agora carregar os dados que serão utilizados nessa aula. Eles estão no formato csv e foram disponibilizados em uma url.\n",
        "\n",
        "Para isso, utilizaremos a função `read_csv` da `pandas`. Ao chamar essa função, vamos informar a url na qual está o arquivo, bem como o separador utilizado e também a codificação do arquivo.\n",
        "\n",
        "Como arquivos csv podem vir de diversas fontes, essas fontes podem alterar a codificação do arquivo para que, por exemplo, possam ser usados caracteres especiais, formatos de datas específicos, etc."
      ],
      "metadata": {
        "id": "FCOdhr80iVZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/flavio-mota/introd-analise-dados/main/bolsistas-de-iniciacao-cientifica.csv'\n",
        "df = pd.read_csv(url, sep=';', encoding='latin-1')"
      ],
      "metadata": {
        "id": "CoCVZJ9WYpnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uma vez carregado na estrutura `DataFrame`, podemos utilizar todos os recursos da biblioteca pandas para realizar operações com nossos dados. Vamos começar analisando os 5 primeiros registros do conjunto:"
      ],
      "metadata": {
        "id": "znGDP5v_jt_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "TiBxmf7MYz1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos verificar as dimensões desse arquivo, ou seja, quantas linhas e quantas colunas temos:"
      ],
      "metadata": {
        "id": "RSR-7HQ2kGuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "FQqu8Hv-kMdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos verificar também quais os tipos de dados que a `pandas` interpretou ao carregar os dados:"
      ],
      "metadata": {
        "id": "nc6NdcxOyKER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "ocjM4GXEyRfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado retornado apresenta que 12 colunas armazenam dados do tipo <code>object</code>. O tipo <code>object</code> pela documentação da biblioteca pandas, representa um tipo de \"objeto arbitrário\". As cadeias de caracteres também são entendidas pela biblioteca como sendo desse tipo.\n",
        "\n",
        "As 2 últimas colunas foram interpretadas como valores numéricos.\n",
        "\n",
        "Além disso, já é possível perceber que nem todas as colunas tem todos os valores presentes."
      ],
      "metadata": {
        "id": "k_mH53fRzPR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dados ausentes\n",
        "\n",
        "Dados ausentes são comuns em muitas aplicações de análise de dados. A `pandas` tenta deixar o trabalho com dados ausentes menos problemático.\n",
        "\n",
        "A biblioteca referencia os dados ausentes como **NA**, do inglês Not Available (indísponivel). Esses dados NA podem ser dados realmente inexistentes ou dados que existem, mas não foram observados, por problemas com a coleta de dados, por exemplo.\n",
        "\n",
        "Ao limpar os dados para análise, em geral é importante fazer a análise nos próprios dados ausentes a fim de identificar problemas em sua coleta ou possíveis distorções provocadas por dados ausentes.\n",
        "\n",
        "Podemos verificar quantos dados ausentes temos por coluna usando o código abaixo:"
      ],
      "metadata": {
        "id": "Ksops8nrkUvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "null_df = df.isnull().sum()\n",
        "null_df"
      ],
      "metadata": {
        "id": "d3LfwrWSZQe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Existem algumas funções do pandas que podemos utilizar para tratar dados ausentes:\n",
        "\n",
        "| **Função** | **Descrição**                                                                                                                                                         |\n",
        "|------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| `dropna()`   | Remove linhas ou colunas que contêm valores ausentes (NaN).<br>Você pode especificar um limite de quantos valores ausentes<br> são aceitáveis antes de uma linha ou coluna ser descartada. |\n",
        "| `fillna()`   | Substitui os valores ausentes em um DataFrame por um valor específico <br>ou usando um método, como 'ffill' (forward fill) para preencher com o último<br> valor válido anterior ou 'bfill' (backward fill) para preencher com o próximo valor válido. |\n",
        "| `isnull()`   | Retorna um objeto booleano do mesmo tamanho que o DataFrame,<br> onde cada elemento é `True` se o correspondente no DataFrame original<br> for um valor ausente (NaN ou None).  |\n",
        "| `notnull()`  | Funciona como o oposto de `isnull()`: retorna `True` para cada elemento <br> que não é um valor ausente (NaN ou None).                                                        |\n",
        ""
      ],
      "metadata": {
        "id": "qpgz6KuVpeUW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos começar filtrando os dados ausentes. Para isso, vamos descartar as linhas nas quais a coluna Campus: [Itajubá] está em branco:"
      ],
      "metadata": {
        "id": "18tv1PrHtASI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_limpo = df.copy()\n",
        "df_limpo = df_limpo.dropna(subset=['Campus: [Itajubá]'])\n",
        "null_df = df_limpo.isnull().sum()\n",
        "null_df"
      ],
      "metadata": {
        "id": "SgfSGprhaFpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "Vamos considerar agora a coluna ValorBolsa. São 13 ocorrências de valores nulos. Nesse caso, não vamos descartar esses registros, mas sim substituir os valores ausentes por 0.\n"
      ],
      "metadata": {
        "id": "rqokuTcZuQxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_limpo['ValorBolsa'] = df_limpo['ValorBolsa'].fillna(0)\n",
        "null_df = df_limpo.isnull().sum()\n",
        "null_df"
      ],
      "metadata": {
        "id": "2iXiHaafaqCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por hora, vamos apenas excluir os outros registros que tem ocorrência de valores ausentes:"
      ],
      "metadata": {
        "id": "Vt0T5eBFNHzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_limpo.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "Eky5z7cvNNMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Vamos agora trabalhar com alguns dados textuais.\n",
        "Primeiramente, vamos selecionar algumas colunas e transformar o texto dessas colunas em maísculas. Primeiro contamos as ocorrências distintas de termos sem essa operação e depois de aplicada a operação, verificamos como estão os dados:\n",
        "\n"
      ],
      "metadata": {
        "id": "hloemKRIxYXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_limpo['Modalidade do Programa de Bolsa:'].value_counts()"
      ],
      "metadata": {
        "id": "LJ5Y_GSr2CZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_limpo['Modalidade do Programa de Bolsa:'] = df_limpo['Modalidade do Programa de Bolsa:'].str.upper()\n",
        "df_limpo['Modalidade do Programa de Bolsa:'].value_counts()"
      ],
      "metadata": {
        "id": "i2kZyg4Q4g5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_limpo['Instituto'].value_counts()"
      ],
      "metadata": {
        "id": "u96v6aG_2WQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_limpo['Instituto'] = df_limpo['Instituto'].str.upper()\n",
        "df_limpo['Instituto'].value_counts()"
      ],
      "metadata": {
        "id": "5LYqHvP63eMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_limpo['Órgão de financiamento'] = df_limpo['Órgão de financiamento'].str.upper()\n",
        "df_limpo['Órgão de financiamento'].value_counts()"
      ],
      "metadata": {
        "id": "ZiLEPacSM8q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Podemos verificar que mesmo colocando todas as letras em maíusculo, o campo **Órgão de financiamento** tem algumas inconsistências.\n",
        "\n",
        "Existem valores que se parecem muito. Vamos nos certificar quais são as strings semelhantes a biblioteca para comparar strings `fuzzywuzzy`. Primeiro, definimos uma função que será responsável por comparar as strings:"
      ],
      "metadata": {
        "id": "GZcSucYd6ItF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encontrar_similares(nome, lista, limite=70):\n",
        "    # 'limite' define o score mínimo para considerar uma correspondência\n",
        "    similares = process.extractBests(nome, lista, scorer=fuzz.token_sort_ratio, score_cutoff=limite)\n",
        "    return similares"
      ],
      "metadata": {
        "id": "elDLx0yaJseS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos agora extrair os nomes únicos que existem no campo **Órgão de financiamento**:"
      ],
      "metadata": {
        "id": "5SoMu7wXJvXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nomes_unicos = df_limpo['Órgão de financiamento'].unique()"
      ],
      "metadata": {
        "id": "2m9PgmmkKHyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, para cada nome único, vamos encontrar os similares e associar uma pontuação de similaridade. Depois, são apresentados os resultados dos nomes e qual a similaridade dos outros com ele:"
      ],
      "metadata": {
        "id": "4qsDAaUzKQx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dicionário para guardar as sugestões\n",
        "sugestoes = {}\n",
        "\n",
        "for nome in nomes_unicos:\n",
        "    # Encontra nomes similares com um score de similaridade acima de 80\n",
        "    resultados = encontrar_similares(nome, nomes_unicos)\n",
        "    if len(resultados) > 1:\n",
        "        # Guarda as sugestões apenas se existirem múltiplos itens similares\n",
        "        sugestoes[nome] = resultados\n",
        "\n",
        "# Exibir as sugestões\n",
        "for nome, similares in sugestoes.items():\n",
        "    print(f'Original: {nome}')\n",
        "    for similar, score in similares:\n",
        "        print(f'  Similar: {similar} (Score: {score})')\n",
        "    print('\\n')"
      ],
      "metadata": {
        "id": "keSvMssP6WRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos alterar as dferentes ocorrências de FAPEMIG e CNPq:"
      ],
      "metadata": {
        "id": "9nHhc64eKrVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lista_substituicoes = {'CMPQ':'CNPQ',\n",
        "                       'UniAO': 'UNIÃO',\n",
        "                       'FAPEMING': 'FAPEMIG'\n",
        "                       }\n",
        "df_limpo['Órgão de financiamento'] = df_limpo['Órgão de financiamento'].replace(lista_substituicoes)\n",
        "df_limpo['Órgão de financiamento'].value_counts()"
      ],
      "metadata": {
        "id": "6ZaFlqDsHGyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Vamos analisar agora o campo `Implementação`.\n"
      ],
      "metadata": {
        "id": "1GIpRbu6OcCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_limpo['Implementação'].value_counts()"
      ],
      "metadata": {
        "id": "uJAtBD_kLrAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para esse campo, iremos fazer uma transformação para que os valores sejam datas:"
      ],
      "metadata": {
        "id": "Lnne_BjRPabb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_limpo['Implementação'] = pd.to_datetime(df_limpo['Implementação'], format='%d/%m/%Y')\n",
        "df_limpo['Implementação'].value_counts()"
      ],
      "metadata": {
        "id": "Y7cmW8BOPTNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora que o formato do dado é um formato próprio para datas, podemos realizar algumas operações no campo com mais facilidade, como extrair o mês:"
      ],
      "metadata": {
        "id": "PEF5yBrsQNt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_limpo['mes_implementacao'] = df_limpo['Implementação'].dt.month\n",
        "df_limpo['mes_implementacao'].value_counts()"
      ],
      "metadata": {
        "id": "luFKwYfJQGCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Por fim, vamos dividir as informações que estão no campo **Vigência**:\n"
      ],
      "metadata": {
        "id": "vMTcq3v3Q5yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_limpo['Vigência'].value_counts()"
      ],
      "metadata": {
        "id": "k796VRhTQy9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serão criados dois novos campos: inicio e fim, com as devidas datas. Depois os campos serão convertidos para o tipo data:"
      ],
      "metadata": {
        "id": "F5M6wkV3RujV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_limpo[['inicio', 'fim']] = df_limpo['Vigência'].str.split(' a ', expand=True)\n",
        "df_limpo['inicio'] = pd.to_datetime(df_limpo['inicio'], format='%m/%Y')\n",
        "df_limpo['fim'] = pd.to_datetime(df_limpo['fim'], format='%m/%Y')\n",
        "print(df_limpo['inicio'].value_counts())\n",
        "print(df_limpo['fim'].value_counts())"
      ],
      "metadata": {
        "id": "ZAdUBl62RHKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos agora criar um campo chamado duração baseado na diferença entre o início e fim da vigência:\n"
      ],
      "metadata": {
        "id": "yB-GjVgkSzXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_limpo['duração_dias'] = (df_limpo['fim'] - df_limpo['inicio']).dt.days\n",
        "\n",
        "df_limpo['duração_meses'] = df_limpo['duração_dias'] // 30\n",
        "\n",
        "print(df_limpo['duração_dias'].value_counts())\n",
        "print(df_limpo['duração_meses'].value_counts())"
      ],
      "metadata": {
        "id": "zXOCwhm_SSWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por fim, podemos salvar as aterações que fizemos no csv em um novo csv:"
      ],
      "metadata": {
        "id": "1lL6jWUCUu06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_limpo.to_csv('bolsistas-de-iniciacao-cientifica-limpo.csv',\n",
        "                sep=';',\n",
        "                index=False,\n",
        "                encoding='latin-1')"
      ],
      "metadata": {
        "id": "vG8gkyqlVCV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yjMehE_zVQgw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}